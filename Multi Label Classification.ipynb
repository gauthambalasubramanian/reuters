{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "01bfdb74-1af7-4b2c-8694-e111e6cf64dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import random\n",
    "from spacy.util import minibatch\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import string\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55a327a4-c62b-4842-b818-9f4e401e022c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('multi_label_df.csv')\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "227125c4-49ab-43ba-85aa-23a08554b54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_classes = ['trade', 'grain', 'crude', 'nat-gas', 'corn', 'rice', 'sugar', 'veg-oil', 'ship', 'coffee', 'wheat', 'gold', 'acq', 'interest', 'money-fx', 'copper', 'ipi', 'carcass', 'livestock', 'oilseed', 'soybean', 'earn', 'bop', 'gas', 'jobs', 'cpi', 'gnp', 'dlr', 'yen', 'cocoa', 'cotton', 'money-supply', 'iron-steel', 'alum', 'reserves', 'barley']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c1ed2b7-fc36-4b16-8fa2-6db7b2caf446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import spacy\n",
    "import pandas as pd\n",
    "import re\n",
    "from spacy.tokens import DocBin\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d6e2b80-1945-4fd7-895f-bbe6fc67c86e",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5d2e50e-142d-417f-8009-b619de57de61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df, embed, unique_classes = unique_classes):\n",
    "    '''\n",
    "    Preprocess the dataframe into spacy pipeline for later classification\n",
    "    ---\n",
    "    Input:\n",
    "    df (DataFrame): Pandas dataframe containing the raw text and outputs.\n",
    "    embed (str): Name of pipeline embedding used\n",
    "\n",
    "    Output:\n",
    "    df (DataFrame): Preprocessed input dataframe\n",
    "    docs (doc): SpaCy doc object that stores text data along with classification\n",
    "    '''\n",
    "\n",
    "\n",
    "    # Store the data into tuples\n",
    "    data = tuple(zip(df['text'].tolist(), df['filtered_labels'].tolist())) \n",
    "    \n",
    "    # Load English library from SpaCy\n",
    "    nlp=spacy.load(embed)\n",
    "    # print(data[0])\n",
    "\n",
    "    # Storage for docs\n",
    "    docs = []\n",
    "\n",
    "    # One-hot encoding for the classifications\n",
    "    for doc, label in tqdm(nlp.pipe(data, as_tuples=True), total = len(data)):\n",
    "        for class_name in unique_classes:\n",
    "            if class_name in label:\n",
    "                doc.cats[class_name] = 1\n",
    "            else:\n",
    "                doc.cats[class_name] = 0\n",
    "        docs.append(doc)\n",
    "    return df, docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89663b47-3e04-4dc8-a447-157c8ca09626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
      "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
      "config/multi_config.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train multi_config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy init fill-config config/base_multi.cfg config/multi_config.cfg "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8475cb75-19b4-4513-ad94-a7c8035f04d2",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87ee66b4-6d88-4f4a-b738-2d78bebd9b88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gautham/Documents/personal/reuters/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8630/8630 [02:23<00:00, 60.04it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2158/2158 [00:36<00:00, 58.75it/s]\n"
     ]
    }
   ],
   "source": [
    "# Covert the train and test dataframes to .spacy files for training\n",
    "\n",
    "# Preprocess the dataframes for train data\n",
    "train_data, train_docs = preprocess(train_df,\"en_core_web_sm\")\n",
    "# Save data and docs in a binary file to disc\n",
    "doc_bin = DocBin(docs=train_docs)\n",
    "doc_bin.to_disk(\"data/spacy_data/textcat_train_multi.spacy\")\n",
    "\n",
    "# Preprocess the dataframes for test data\n",
    "test_data, test_docs = preprocess(test_df,\"en_core_web_sm\")\n",
    "# Save data and docs in a binary file to disc\n",
    "doc_bin = DocBin(docs=test_docs)\n",
    "doc_bin.to_disk(\"data/spacy_data/textcat_valid_multi.spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7afd1aaa-447e-4734-a45d-a1b4127b88aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN docs: 8630 with 167327 entities\n",
      "DEV docs: 2158 with 42018 entities\n"
     ]
    }
   ],
   "source": [
    "# View the entities in the train and test docs\n",
    "train_loc = \"data/spacy_data/textcat_train_multi.spacy\"\n",
    "dev_loc = \"data/spacy_data/textcat_valid_multi.spacy\"\n",
    "\n",
    "# Load library and train data\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "doc_bin = DocBin().from_disk(train_loc)\n",
    "docs = list(doc_bin.get_docs(nlp.vocab))\n",
    "entities = 0\n",
    "\n",
    "# Iterate through the docs\n",
    "for doc in docs:\n",
    "    entities += len(doc.ents)\n",
    "print(f\"TRAIN docs: {len(docs)} with {entities} entities\")\n",
    "\n",
    "# Load library and test data\n",
    "doc_bin = DocBin().from_disk(dev_loc)\n",
    "docs = list(doc_bin.get_docs(nlp.vocab))\n",
    "entities = 0\n",
    "\n",
    "# Iterate through the docs\n",
    "for doc in docs:\n",
    "    entities += len(doc.ents)\n",
    "print(f\"DEV docs: {len(docs)} with {entities} entities\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "232f4453-b600-411d-8144-6bfd98c7c191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-08-20 20:27:50,430] [DEBUG] Config overrides from CLI: ['paths.train', 'paths.dev']\n",
      "\u001b[38;5;2m✔ Created output directory: data/multi_textcat_output\u001b[0m\n",
      "\u001b[38;5;4mℹ Saving to output directory: data/multi_textcat_output\u001b[0m\n",
      "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
      "\u001b[38;5;4mℹ To switch to GPU 0, use the option: --gpu-id 0\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "[2023-08-20 20:27:51,094] [INFO] Set up nlp object from config\n",
      "[2023-08-20 20:27:51,111] [DEBUG] Loading corpus from path: data/spacy_data/textcat_valid_multi.spacy\n",
      "[2023-08-20 20:27:51,113] [DEBUG] Loading corpus from path: data/spacy_data/textcat_train_multi.spacy\n",
      "[2023-08-20 20:27:51,114] [INFO] Pipeline: ['textcat_multilabel']\n",
      "[2023-08-20 20:27:51,117] [INFO] Created vocabulary\n",
      "[2023-08-20 20:27:51,117] [INFO] Finished initializing nlp object\n",
      "[2023-08-20 20:28:04,212] [INFO] Initialized pipeline components: ['textcat_multilabel']\n",
      "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "[2023-08-20 20:28:04,232] [DEBUG] Loading corpus from path: data/spacy_data/textcat_valid_multi.spacy\n",
      "[2023-08-20 20:28:04,234] [DEBUG] Loading corpus from path: data/spacy_data/textcat_train_multi.spacy\n",
      "\u001b[38;5;4mℹ Pipeline: ['textcat_multilabel']\u001b[0m\n",
      "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
      "E    #       LOSS TEXTC...  CATS_SCORE  SCORE \n",
      "---  ------  -------------  ----------  ------\n",
      "  0       0           0.25       39.34    0.39\n",
      "  0     200           7.78       43.14    0.43\n",
      "  0     400           4.39       45.38    0.45\n",
      "  0     600           4.04       46.72    0.47\n",
      "  0     800           3.85       48.59    0.49\n",
      "  0    1000           3.88       49.94    0.50\n",
      "  0    1200           3.53       50.62    0.51\n",
      "  0    1400           3.47       51.28    0.51\n",
      "  0    1600           3.05       51.52    0.52\n",
      "  0    1800           3.08       52.25    0.52\n",
      "  0    2000           2.67       53.47    0.53\n",
      "  0    2200           2.94       54.70    0.55\n",
      "  0    2400           2.73       55.90    0.56\n",
      "  0    2600           2.52       56.67    0.57\n",
      "  0    2800           2.75       57.33    0.57\n",
      "  0    3000           2.49       58.91    0.59\n",
      "  0    3200           2.93       61.14    0.61\n",
      "  1    3400           1.80       62.19    0.62\n",
      "  1    3600           2.14       63.59    0.64\n",
      "  1    3800           1.72       64.91    0.65\n",
      "  1    4000           1.78       65.68    0.66\n",
      "  1    4200           1.87       66.34    0.66\n",
      "  1    4400           2.03       66.98    0.67\n",
      "  1    4600           1.75       68.42    0.68\n",
      "  1    4800           1.47       69.38    0.69\n",
      "  2    5000           1.41       70.30    0.70\n",
      "  2    5200           1.70       71.30    0.71\n",
      "  2    5400           1.04       71.28    0.71\n",
      "  2    5600           1.66       72.23    0.72\n",
      "  2    5800           1.56       72.83    0.73\n",
      "  2    6000           1.13       73.09    0.73\n",
      "  2    6200           1.21       73.01    0.73\n",
      "  2    6400           1.12       73.79    0.74\n",
      "  3    6600           1.68       73.69    0.74\n",
      "  3    6800           1.23       74.37    0.74\n",
      "  3    7000           0.92       74.33    0.74\n",
      "  3    7200           0.86       74.29    0.74\n",
      "  3    7400           1.58       74.54    0.75\n",
      "  3    7600           0.94       74.51    0.75\n",
      "  3    7800           1.05       74.83    0.75\n",
      "  3    8000           1.21       75.02    0.75\n",
      "  4    8200           1.15       75.20    0.75\n",
      "  4    8400           0.85       74.93    0.75\n",
      "  4    8600           1.23       75.10    0.75\n",
      "  4    8800           0.93       75.43    0.75\n",
      "  4    9000           0.84       75.59    0.76\n",
      "  4    9200           1.16       75.81    0.76\n",
      "  4    9400           1.22       75.95    0.76\n",
      "  4    9600           1.08       75.62    0.76\n",
      "  5    9800           1.31       75.74    0.76\n",
      "  5   10000           1.45       76.11    0.76\n",
      "  5   10200           0.82       75.77    0.76\n",
      "  5   10400           1.01       76.03    0.76\n",
      "  5   10600           1.15       76.48    0.76\n",
      "  5   10800           0.99       76.31    0.76\n",
      "  5   11000           0.87       76.34    0.76\n",
      "  5   11200           0.74       76.18    0.76\n",
      "  6   11400           1.06       76.57    0.77\n",
      "  6   11600           1.00       76.42    0.76\n",
      "  6   11800           0.71       76.56    0.77\n",
      "  6   12000           0.84       76.95    0.77\n",
      "  6   12200           0.69       76.58    0.77\n",
      "  6   12400           1.47       77.20    0.77\n",
      "  6   12600           1.34       77.14    0.77\n",
      "  6   12800           0.83       77.55    0.78\n",
      "  7   13000           0.83       77.43    0.77\n",
      "  7   13200           0.72       77.77    0.78\n",
      "  7   13400           0.97       77.79    0.78\n",
      "  7   13600           1.06       77.93    0.78\n",
      "  7   13800           0.68       78.21    0.78\n",
      "  7   14000           0.86       78.65    0.79\n",
      "  7   14200           0.81       78.36    0.78\n",
      "  7   14400           0.77       78.55    0.79\n",
      "  7   14600           1.15       78.82    0.79\n",
      "  8   14800           1.05       79.01    0.79\n",
      "  8   15000           0.51       78.91    0.79\n",
      "  8   15200           0.89       78.77    0.79\n",
      "  8   15400           0.83       79.21    0.79\n",
      "  8   15600           1.01       79.19    0.79\n",
      "  8   15800           0.83       79.45    0.79\n",
      "  8   16000           0.51       79.31    0.79\n",
      "  8   16200           0.93       79.37    0.79\n",
      "  9   16400           0.95       80.14    0.80\n",
      "  9   16600           0.85       80.04    0.80\n",
      "  9   16800           0.60       80.42    0.80\n",
      "  9   17000           0.72       79.93    0.80\n",
      "  9   17200           0.64       79.92    0.80\n",
      "  9   17400           0.83       80.48    0.80\n",
      "  9   17600           0.94       79.70    0.80\n",
      "  9   17800           0.84       80.91    0.81\n",
      " 10   18000           0.77       81.06    0.81\n",
      " 10   18200           0.87       81.24    0.81\n",
      " 10   18400           0.75       81.04    0.81\n",
      " 10   18600           0.76       81.47    0.81\n",
      " 10   18800           0.45       81.30    0.81\n",
      " 10   19000           0.52       81.44    0.81\n",
      " 10   19200           0.91       81.44    0.81\n",
      " 10   19400           0.66       81.51    0.82\n",
      " 11   19600           0.85       81.00    0.81\n",
      " 11   19800           0.65       81.30    0.81\n",
      " 11   20000           0.68       81.95    0.82\n",
      "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
      "data/multi_textcat_output/model-last\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy train config/multi_config.cfg --verbose --output data/multi_textcat_output --paths.train data/spacy_data/textcat_train_multi.spacy --paths.dev data/spacy_data/textcat_valid_multi.spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9816c8e-d591-4f20-9b36-573c75c47f8b",
   "metadata": {},
   "source": [
    "## Metrics Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "edc6a7af-3cca-4373-b587-7a472ee3b83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spacy_pred(dict):\n",
    "    return_dict = {}\n",
    "    for key, value in dict.items():\n",
    "        if value >=0.5:\n",
    "            return_dict[key] = value\n",
    "    return return_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2b87c132-2800-41c3-bb5d-e3374aaef394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify model for English model\n",
    "nlp_model = spacy.load(\"data/multi_textcat_output/model-best\")\n",
    "test_text = test_data.text.tolist()\n",
    "test_cats = test_data['filtered_labels'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "bc487981-5371-46e2-abb2-a265a435cc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_multilabel_onehot(labels, unique_classes=unique_classes):\n",
    "    append_list = []\n",
    "    for item in unique_classes:\n",
    "        if item in labels:\n",
    "            append_list.append(1)\n",
    "        else:\n",
    "            append_list.append(0)\n",
    "    return np.array(append_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b1030331-0881-40a2-b694-eaea0f317ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['multi_target'] = test_df['labels'].apply(lambda x: create_multilabel_onehot(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1a61c7-41cc-45ad-94b6-50779dcd2a3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "3b983910-a346-48b8-8b28-2ba689ebce08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2158/2158 [00:00<00:00, 2537.17it/s]\n"
     ]
    }
   ],
   "source": [
    "pred_list = []\n",
    "for item in tqdm(test_text, total=len(test_text)):\n",
    "    doc = nlp_model(item)\n",
    "    pred = get_spacy_pred(doc.cats)\n",
    "    one_hot = create_multilabel_onehot(pred.keys())\n",
    "    pred_list.append(one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80dc9e7d-57a3-4224-8a68-468fa4c80120",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bbb21d-2795-4f98-a867-a750d54085d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "2633ed19-f72d-4f9b-b41e-e31c536ada7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import  multilabel_confusion_matrix, hamming_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "fe88d358-cd76-4cd4-9635-9fe8de1ef971",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[2058,    7],\n",
       "        [  32,   61]],\n",
       "\n",
       "       [[2024,    6],\n",
       "        [  26,  102]],\n",
       "\n",
       "       [[2045,    7],\n",
       "        [  26,   80]],\n",
       "\n",
       "       [[2127,    0],\n",
       "        [  20,   11]],\n",
       "\n",
       "       [[2101,    4],\n",
       "        [  20,   33]],\n",
       "\n",
       "       [[2139,    0],\n",
       "        [  19,    0]],\n",
       "\n",
       "       [[2117,    6],\n",
       "        [  11,   24]],\n",
       "\n",
       "       [[2135,    1],\n",
       "        [  10,   12]],\n",
       "\n",
       "       [[2095,    3],\n",
       "        [  21,   39]],\n",
       "\n",
       "       [[2130,    0],\n",
       "        [   8,   20]],\n",
       "\n",
       "       [[2092,    6],\n",
       "        [  21,   39]],\n",
       "\n",
       "       [[2125,    0],\n",
       "        [  13,   20]],\n",
       "\n",
       "       [[1680,    9],\n",
       "        [  31,  438]],\n",
       "\n",
       "       [[2035,   11],\n",
       "        [  29,   83]],\n",
       "\n",
       "       [[2007,   18],\n",
       "        [  28,  105]],\n",
       "\n",
       "       [[2149,    0],\n",
       "        [   4,    5]],\n",
       "\n",
       "       [[2150,    0],\n",
       "        [   5,    3]],\n",
       "\n",
       "       [[2143,    0],\n",
       "        [  15,    0]],\n",
       "\n",
       "       [[2137,    0],\n",
       "        [  18,    3]],\n",
       "\n",
       "       [[2132,    1],\n",
       "        [  17,    8]],\n",
       "\n",
       "       [[2138,    3],\n",
       "        [  14,    3]],\n",
       "\n",
       "       [[1360,   11],\n",
       "        [  28,  759]],\n",
       "\n",
       "       [[2131,    7],\n",
       "        [   8,   12]],\n",
       "\n",
       "       [[2122,    2],\n",
       "        [  21,   13]],\n",
       "\n",
       "       [[2145,    0],\n",
       "        [   7,    6]],\n",
       "\n",
       "       [[2136,    2],\n",
       "        [  11,    9]],\n",
       "\n",
       "       [[2124,    0],\n",
       "        [  14,   20]],\n",
       "\n",
       "       [[2119,    3],\n",
       "        [  20,   16]],\n",
       "\n",
       "       [[2145,    0],\n",
       "        [  13,    0]],\n",
       "\n",
       "       [[2140,    1],\n",
       "        [   5,   12]],\n",
       "\n",
       "       [[2147,    0],\n",
       "        [  11,    0]],\n",
       "\n",
       "       [[2121,    3],\n",
       "        [   5,   29]],\n",
       "\n",
       "       [[2154,    0],\n",
       "        [   4,    0]],\n",
       "\n",
       "       [[2151,    0],\n",
       "        [   6,    1]],\n",
       "\n",
       "       [[2145,    0],\n",
       "        [   5,    8]],\n",
       "\n",
       "       [[2151,    1],\n",
       "        [   3,    3]]])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multilabel_confusion_matrix(np.array(test_df['multi_target'].to_list()), np.array(pred_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "5d692c56-d6d7-43b8-9408-8cad50649ced",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.008508392544537122"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hamming_loss(np.array(test_df['multi_target'].to_list()), np.array(pred_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851f51e1-3e03-4c87-81f0-d133879b0570",
   "metadata": {},
   "source": [
    "> The model achieves a Hamming Loss of **0.0085** which is considerably good for a primitive model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4904c7-3963-4a0f-bc35-e4e68407bdf1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
