{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba3bf2c9-85ed-4197-8d2f-7e4f40d5afbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import random\n",
    "from spacy.util import minibatch\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import string"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4199d65d-a59f-4ea5-bfde-7b4ae6461dbf",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "raw",
   "id": "361f834b-5f76-45e2-a25c-933f8269d70f",
   "metadata": {},
   "source": [
    "!python -m spacy download en_core_web_trf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575e7993-a5dd-492f-a45b-52c513aa08f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c5a889b4-19e4-4c62-a4cd-b21181c43ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('single_label_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "85ea9580-4a15-4def-937c-b29edb875752",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_classes = df['top_label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fc974dfa-6ef1-4ec2-baa8-3459385d94bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df['top_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7132796c-5975-48f1-88b1-eeef4e306733",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "71a9faab-857d-42e9-a8f7-b7b2c07af4a3",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2ee107d9-197e-4a07-b000-77da3a1fe27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "train_df['encoded_label'] = encoder.fit_transform(train_df['top_label'])\n",
    "test_df['encoded_label']  = encoder.transform(test_df['top_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9663ee6d-c53c-48ff-ac43-841ee803c555",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4f58a524-2314-4a98-9611-000ff3ae6524",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "\n",
    "# Load the English library from SpaCy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# # Add contextual spell check to pipeline\n",
    "# nlp.add_pipe(\"contextual spellchecker\", config={\"max_edit_dist\": 5})    \n",
    "\n",
    "# Create list of punctuation marks\n",
    "punctuations = string.punctuation\n",
    "\n",
    "# Create list of stopwords from spaCy\n",
    "stopwords = spacy.lang.en.stop_words.STOP_WORDS\n",
    "\n",
    "\n",
    "# Creat tokenizer function\n",
    "def spacy_tokenizer(sentence):\n",
    "    # Create token object from spacy\n",
    "    tokens = nlp(sentence)\n",
    "\n",
    "    # Correct spelling\n",
    "    # tokens = tokens._.outcome_spellCheck\n",
    "    # tokens = nlp(tokens)\n",
    "\n",
    "    # Lemmatize each token and convert each token into lowercase\n",
    "    tokens = [word.lemma_.lower().strip() if word.lemma_ != \"PROPN\" else word.lower_ for word in tokens]\n",
    "    \n",
    "    # Remove stopwords\n",
    "    tokens = [word for word in tokens if word not in stopwords and word not in punctuations]\n",
    "    \n",
    "    \n",
    "    # return preprocessed list of tokens\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488a56c9-f62a-4b7f-a487-56e70e4ddd27",
   "metadata": {},
   "source": [
    "## Bag-of-words model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "79425882-a248-4130-8b22-4c8d2bf81bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Custom transformer class using spaCy\n",
    "class predictors(TransformerMixin):\n",
    "    def transform(self, X, **transform_params):\n",
    "        # Implement clean_text\n",
    "        return [clean_text(text) for text in X]\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "\n",
    "    def get_params(self, deep=True):\n",
    "        return {}\n",
    "\n",
    "# Basic function to clean the text\n",
    "def clean_text(text):\n",
    "    # Remove spaces and converte text into lowercase\n",
    "    return text.strip().lower()\n",
    "\n",
    "# Bag-of-words data transformation\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "bow_vector = CountVectorizer(tokenizer = spacy_tokenizer, ngram_range=(1,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e89c9cec-4983-4667-8d37-dc9dac409515",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df['text']\n",
    "X_test = test_df['text']\n",
    "y_train = train_df['encoded_label']\n",
    "y_test = test_df['encoded_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "03283cb3-5e24-4129-9c03-0ab2bdc78e31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gautham/Documents/personal/reuters/venv/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;cleaner&#x27;, &lt;__main__.predictors object at 0x12ff73c10&gt;),\n",
       "                (&#x27;vectorizer&#x27;,\n",
       "                 CountVectorizer(tokenizer=&lt;function spacy_tokenizer at 0x12e90d1b0&gt;)),\n",
       "                (&#x27;classifier&#x27;, MultinomialNB())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;cleaner&#x27;, &lt;__main__.predictors object at 0x12ff73c10&gt;),\n",
       "                (&#x27;vectorizer&#x27;,\n",
       "                 CountVectorizer(tokenizer=&lt;function spacy_tokenizer at 0x12e90d1b0&gt;)),\n",
       "                (&#x27;classifier&#x27;, MultinomialNB())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">predictors</label><div class=\"sk-toggleable__content\"><pre>&lt;__main__.predictors object at 0x12ff73c10&gt;</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer(tokenizer=&lt;function spacy_tokenizer at 0x12e90d1b0&gt;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('cleaner', <__main__.predictors object at 0x12ff73c10>),\n",
       "                ('vectorizer',\n",
       "                 CountVectorizer(tokenizer=<function spacy_tokenizer at 0x12e90d1b0>)),\n",
       "                ('classifier', MultinomialNB())])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multinomial Naive Bayes Classifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "classifier = MultinomialNB()\n",
    "\n",
    "# Create pipeline using Bag of Words\n",
    "pipe_NB = Pipeline([(\"cleaner\", predictors()),\n",
    "                 ('vectorizer', bow_vector),\n",
    "                 ('classifier', classifier)])\n",
    "\n",
    "# model generation\n",
    "pipe_NB.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0a20c8ef-b52f-40df-bc80-46d0db59807a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gautham/Documents/personal/reuters/venv/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/gautham/Documents/personal/reuters/venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;cleaner&#x27;, &lt;__main__.predictors object at 0x12dc333d0&gt;),\n",
       "                (&#x27;vectorizer&#x27;,\n",
       "                 CountVectorizer(tokenizer=&lt;function spacy_tokenizer at 0x12e90d1b0&gt;)),\n",
       "                (&#x27;classifier&#x27;, LogisticRegression())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;cleaner&#x27;, &lt;__main__.predictors object at 0x12dc333d0&gt;),\n",
       "                (&#x27;vectorizer&#x27;,\n",
       "                 CountVectorizer(tokenizer=&lt;function spacy_tokenizer at 0x12e90d1b0&gt;)),\n",
       "                (&#x27;classifier&#x27;, LogisticRegression())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">predictors</label><div class=\"sk-toggleable__content\"><pre>&lt;__main__.predictors object at 0x12dc333d0&gt;</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer(tokenizer=&lt;function spacy_tokenizer at 0x12e90d1b0&gt;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('cleaner', <__main__.predictors object at 0x12dc333d0>),\n",
       "                ('vectorizer',\n",
       "                 CountVectorizer(tokenizer=<function spacy_tokenizer at 0x12e90d1b0>)),\n",
       "                ('classifier', LogisticRegression())])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic Regression Classifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier_log = LogisticRegression()\n",
    "\n",
    "# Create pipeline using Bag of Words\n",
    "pipe_log = Pipeline([(\"cleaner\", predictors()),\n",
    "                 ('vectorizer', bow_vector),\n",
    "                 ('classifier', classifier_log)])\n",
    "\n",
    "# model generation\n",
    "pipe_log.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fd945bef-a43c-45ec-9e45-d0556cc9008c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gautham/Documents/personal/reuters/venv/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;cleaner&#x27;, &lt;__main__.predictors object at 0x12ff73b80&gt;),\n",
       "                (&#x27;vectorizer&#x27;,\n",
       "                 CountVectorizer(tokenizer=&lt;function spacy_tokenizer at 0x12e90d1b0&gt;)),\n",
       "                (&#x27;classifier&#x27;, SVC())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;cleaner&#x27;, &lt;__main__.predictors object at 0x12ff73b80&gt;),\n",
       "                (&#x27;vectorizer&#x27;,\n",
       "                 CountVectorizer(tokenizer=&lt;function spacy_tokenizer at 0x12e90d1b0&gt;)),\n",
       "                (&#x27;classifier&#x27;, SVC())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">predictors</label><div class=\"sk-toggleable__content\"><pre>&lt;__main__.predictors object at 0x12ff73b80&gt;</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer(tokenizer=&lt;function spacy_tokenizer at 0x12e90d1b0&gt;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('cleaner', <__main__.predictors object at 0x12ff73b80>),\n",
       "                ('vectorizer',\n",
       "                 CountVectorizer(tokenizer=<function spacy_tokenizer at 0x12e90d1b0>)),\n",
       "                ('classifier', SVC())])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SVM Classifier\n",
    "from sklearn.svm import SVC\n",
    "classifier_svm = SVC()\n",
    "\n",
    "# Create pipeline using Bag of Words\n",
    "pipe_svm = Pipeline([(\"cleaner\", predictors()),\n",
    "                 ('vectorizer', bow_vector),\n",
    "                 ('classifier', classifier_svm)])\n",
    "\n",
    "# model generation\n",
    "pipe_svm.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af183ac-c58b-4db4-9584-f4147cde9907",
   "metadata": {},
   "source": [
    "### Model metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3747416f-ef4e-4529-b622-2331db84d918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Model:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         acq       0.90      0.97      0.93       470\n",
      "       cocoa       1.00      0.50      0.67        12\n",
      "      coffee       1.00      0.75      0.86        24\n",
      "      copper       1.00      0.40      0.57        10\n",
      "         cpi       1.00      0.53      0.70        15\n",
      "       crude       0.88      0.84      0.86       108\n",
      "        earn       0.98      0.95      0.96       793\n",
      "         gnp       0.82      0.45      0.58        20\n",
      "        gold       0.94      0.70      0.80        23\n",
      "       grain       0.67      0.97      0.79       116\n",
      "    interest       0.88      0.48      0.62        58\n",
      "   livestock       1.00      0.06      0.12        16\n",
      "    money-fx       0.68      0.96      0.79       143\n",
      "money-supply       1.00      0.84      0.91        31\n",
      "     oilseed       0.00      0.00      0.00        16\n",
      "        ship       0.95      0.58      0.72        33\n",
      "       sugar       1.00      0.54      0.70        26\n",
      "       trade       0.66      0.81      0.73        85\n",
      "     veg-oil       0.67      0.13      0.22        15\n",
      "\n",
      "    accuracy                           0.88      2014\n",
      "   macro avg       0.84      0.60      0.66      2014\n",
      "weighted avg       0.89      0.88      0.87      2014\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gautham/Documents/personal/reuters/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/gautham/Documents/personal/reuters/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/gautham/Documents/personal/reuters/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Classification Report\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Predict with a test dataset\n",
    "predicted = pipe_NB.predict(X_test)\n",
    "\n",
    "# Model Accuracy\n",
    "print(\"Naive Bayes Model:\\n\")\n",
    "print(classification_report(y_test, predicted, target_names = encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9419fe5d-7988-42b8-8395-bafe8ad82c44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Model:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         acq       0.96      0.96      0.96       470\n",
      "       cocoa       1.00      1.00      1.00        12\n",
      "      coffee       0.96      1.00      0.98        24\n",
      "      copper       1.00      0.90      0.95        10\n",
      "         cpi       0.87      0.87      0.87        15\n",
      "       crude       0.93      0.84      0.88       108\n",
      "        earn       0.97      0.99      0.98       793\n",
      "         gnp       0.79      0.95      0.86        20\n",
      "        gold       0.96      0.96      0.96        23\n",
      "       grain       0.96      0.93      0.94       116\n",
      "    interest       0.82      0.78      0.80        58\n",
      "   livestock       1.00      0.62      0.77        16\n",
      "    money-fx       0.86      0.91      0.88       143\n",
      "money-supply       0.91      0.94      0.92        31\n",
      "     oilseed       0.67      0.50      0.57        16\n",
      "        ship       0.84      0.82      0.83        33\n",
      "       sugar       0.92      0.92      0.92        26\n",
      "       trade       0.88      0.86      0.87        85\n",
      "     veg-oil       0.50      0.47      0.48        15\n",
      "\n",
      "    accuracy                           0.94      2014\n",
      "   macro avg       0.88      0.85      0.86      2014\n",
      "weighted avg       0.94      0.94      0.94      2014\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification Report\n",
    "from sklearn.metrics import classification_report\n",
    "# Predicting with a test dataset\n",
    "predicted_log = pipe_log.predict(X_test)\n",
    "\n",
    "# Model Accuracy\n",
    "print(\"Logistic Regression Model:\\n\")\n",
    "print(classification_report(y_test, predicted_log, target_names = encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7b719b6b-b25d-45cf-9811-96d1933dca5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Model:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         acq       0.82      0.98      0.89       470\n",
      "       cocoa       1.00      0.75      0.86        12\n",
      "      coffee       0.95      0.88      0.91        24\n",
      "      copper       1.00      0.70      0.82        10\n",
      "         cpi       0.85      0.73      0.79        15\n",
      "       crude       0.92      0.78      0.84       108\n",
      "        earn       0.97      0.98      0.98       793\n",
      "         gnp       0.79      0.55      0.65        20\n",
      "        gold       0.91      0.91      0.91        23\n",
      "       grain       0.87      0.84      0.85       116\n",
      "    interest       0.86      0.66      0.75        58\n",
      "   livestock       1.00      0.06      0.12        16\n",
      "    money-fx       0.82      0.87      0.84       143\n",
      "money-supply       0.93      0.84      0.88        31\n",
      "     oilseed       0.86      0.38      0.52        16\n",
      "        ship       0.92      0.70      0.79        33\n",
      "       sugar       0.95      0.77      0.85        26\n",
      "       trade       0.88      0.78      0.82        85\n",
      "     veg-oil       0.69      0.60      0.64        15\n",
      "\n",
      "    accuracy                           0.90      2014\n",
      "   macro avg       0.89      0.72      0.77      2014\n",
      "weighted avg       0.90      0.90      0.89      2014\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classificatin Report\n",
    "from sklearn.metrics import classification_report\n",
    "# Predicting with a test dataset\n",
    "predicted_svm = pipe_svm.predict(X_test)\n",
    "\n",
    "# Model Accuracy\n",
    "print(\"SVM Model:\\n\")\n",
    "print(classification_report(y_test, predicted_svm, target_names = encoder.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164e5c74-bbc9-4467-be5a-d46ed3136aac",
   "metadata": {},
   "source": [
    "## Neural Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "910359bc-8df7-4aed-a460-e050f9272229",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import spacy\n",
    "import pandas as pd\n",
    "import re\n",
    "from spacy.tokens import DocBin\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e5de6184-d72f-4089-be5f-9ae5a464ab66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df, embed, unique_classes = unique_classes):\n",
    "    '''\n",
    "    Preprocess the dataframe into spacy pipeline for later classification\n",
    "    ---\n",
    "    Input:\n",
    "    df (DataFrame): Pandas dataframe containing the raw text and outputs.\n",
    "    embed (str): Name of pipeline embedding used\n",
    "\n",
    "    Output:\n",
    "    df (DataFrame): Preprocessed input dataframe\n",
    "    docs (doc): SpaCy doc object that stores text data along with classification\n",
    "    '''\n",
    "\n",
    "\n",
    "    # Store the data into tuples\n",
    "    data = tuple(zip(df['text'].tolist(), df['top_label'].tolist())) \n",
    "    \n",
    "    # Load English library from SpaCy\n",
    "    nlp=spacy.load(embed)\n",
    "    # print(data[0])\n",
    "\n",
    "    # Storage for docs\n",
    "    docs = []\n",
    "\n",
    "    # One-hot encoding for the classifications\n",
    "    for doc, label in tqdm(nlp.pipe(data, as_tuples=True), total = len(data)):\n",
    "        for class_name in unique_classes:\n",
    "            if label==class_name:\n",
    "                doc.cats[class_name] = 1\n",
    "            else:\n",
    "                doc.cats[class_name] = 0\n",
    "        docs.append(doc)\n",
    "    return df, docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4389272d-a1f7-4341-ae3d-c9afe8d9e0e3",
   "metadata": {},
   "source": [
    "### Config Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "aa9576dc-b92b-46af-958a-aada3037c52e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
      "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
      "config/config.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy init fill-config config/base_config.cfg config/config.cfg "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fadd8041-1488-4412-b846-e6b0b9e81e30",
   "metadata": {},
   "source": [
    "### Spacy English Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6c3afc9f-00ae-4d63-a488-a96c194fb680",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8056/8056 [02:09<00:00, 62.14it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2014/2014 [00:31<00:00, 63.95it/s]\n"
     ]
    }
   ],
   "source": [
    "# Covert the train and test dataframes to .spacy files for training\n",
    "\n",
    "# Preprocess the dataframes for train data\n",
    "train_data, train_docs = preprocess(train_df,\"en_core_web_sm\")\n",
    "# Save data and docs in a binary file to disc\n",
    "doc_bin = DocBin(docs=train_docs)\n",
    "doc_bin.to_disk(\"data/spacy_data/textcat_train.spacy\")\n",
    "\n",
    "# Preprocess the dataframes for test data\n",
    "test_data, test_docs = preprocess(test_df,\"en_core_web_sm\")\n",
    "# Save data and docs in a binary file to disc\n",
    "doc_bin = DocBin(docs=test_docs)\n",
    "doc_bin.to_disk(\"data/spacy_data/textcat_valid.spacy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6192aade-9a2f-4bde-8725-27ab59ac2442",
   "metadata": {},
   "source": [
    "#### Validate the files and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "84b6d41f-51e1-4d77-80ab-f621d71f17c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN docs: 8056 with 155341 entities\n",
      "DEV docs: 2014 with 38445 entities\n"
     ]
    }
   ],
   "source": [
    "# View the entities in the train and test docs\n",
    "train_loc = \"data/spacy_data/textcat_train.spacy\"\n",
    "dev_loc = \"data/spacy_data/textcat_valid.spacy\"\n",
    "\n",
    "# Load library and train data\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "doc_bin = DocBin().from_disk(train_loc)\n",
    "docs = list(doc_bin.get_docs(nlp.vocab))\n",
    "entities = 0\n",
    "\n",
    "# Iterate through the docs\n",
    "for doc in docs:\n",
    "    entities += len(doc.ents)\n",
    "print(f\"TRAIN docs: {len(docs)} with {entities} entities\")\n",
    "\n",
    "# Load library and test data\n",
    "doc_bin = DocBin().from_disk(dev_loc)\n",
    "docs = list(doc_bin.get_docs(nlp.vocab))\n",
    "entities = 0\n",
    "\n",
    "# Iterate through the docs\n",
    "for doc in docs:\n",
    "    entities += len(doc.ents)\n",
    "print(f\"DEV docs: {len(docs)} with {entities} entities\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "feb8908d-4d4e-411d-b1a7-848e841484b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-08-20 18:49:13,970] [DEBUG] Config overrides from CLI: ['paths.train', 'paths.dev']\n",
      "\u001b[38;5;2m✔ Created output directory: data/textcat_output\u001b[0m\n",
      "\u001b[38;5;4mℹ Saving to output directory: data/textcat_output\u001b[0m\n",
      "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "[2023-08-20 18:49:14,207] [INFO] Set up nlp object from config\n",
      "[2023-08-20 18:49:14,220] [DEBUG] Loading corpus from path: data/spacy_data/textcat_valid.spacy\n",
      "[2023-08-20 18:49:14,221] [DEBUG] Loading corpus from path: data/spacy_data/textcat_train.spacy\n",
      "[2023-08-20 18:49:14,221] [INFO] Pipeline: ['textcat']\n",
      "[2023-08-20 18:49:14,224] [INFO] Created vocabulary\n",
      "[2023-08-20 18:49:14,224] [INFO] Finished initializing nlp object\n",
      "[2023-08-20 18:49:30,863] [INFO] Initialized pipeline components: ['textcat']\n",
      "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "[2023-08-20 18:49:30,879] [DEBUG] Loading corpus from path: data/spacy_data/textcat_valid.spacy\n",
      "[2023-08-20 18:49:30,881] [DEBUG] Loading corpus from path: data/spacy_data/textcat_train.spacy\n",
      "\u001b[38;5;4mℹ Pipeline: ['textcat']\u001b[0m\n",
      "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
      "E    #       LOSS TEXTCAT  CATS_SCORE  SCORE \n",
      "---  ------  ------------  ----------  ------\n",
      "  0       0          0.05        0.79    0.01\n",
      "  0     200          6.74       17.98    0.18\n",
      "  0     400          5.27       30.52    0.31\n",
      "  0     600          3.53       40.08    0.40\n",
      "  0     800          3.34       38.82    0.39\n",
      "  0    1000          3.99       45.29    0.45\n",
      "  0    1200          4.02       48.38    0.48\n",
      "  0    1400          2.93       51.44    0.51\n",
      "  0    1600          3.04       55.69    0.56\n",
      "  0    1800          2.85       58.86    0.59\n",
      "  0    2000          2.29       59.55    0.60\n",
      "  0    2200          2.21       58.67    0.59\n",
      "  0    2400          2.56       60.87    0.61\n",
      "  0    2600          2.39       63.41    0.63\n",
      "  0    2800          1.97       61.44    0.61\n",
      "  0    3000          2.38       63.58    0.64\n",
      "  1    3200          1.57       66.36    0.66\n",
      "  1    3400          1.15       69.62    0.70\n",
      "  1    3600          1.43       70.25    0.70\n",
      "  1    3800          1.00       69.22    0.69\n",
      "  1    4000          1.24       69.86    0.70\n",
      "  1    4200          0.92       69.05    0.69\n",
      "  1    4400          1.12       69.14    0.69\n",
      "  1    4600          1.13       72.77    0.73\n",
      "  2    4800          0.95       74.94    0.75\n",
      "  2    5000          0.82       72.31    0.72\n",
      "  2    5200          0.95       74.02    0.74\n",
      "  2    5400          0.67       73.63    0.74\n",
      "  2    5600          0.84       73.89    0.74\n",
      "  2    5800          0.77       74.36    0.74\n",
      "  2    6000          0.83       75.41    0.75\n",
      "  3    6200          0.70       75.10    0.75\n",
      "  3    6400          0.57       73.22    0.73\n",
      "  3    6600          0.64       74.81    0.75\n",
      "  3    6800          0.60       76.21    0.76\n",
      "  3    7000          0.70       75.32    0.75\n",
      "  3    7200          0.81       74.62    0.75\n",
      "  3    7400          0.63       73.78    0.74\n",
      "  3    7600          0.73       75.34    0.75\n",
      "  4    7800          0.50       76.93    0.77\n",
      "  4    8000          0.50       80.08    0.80\n",
      "  4    8200          0.76       77.20    0.77\n",
      "  4    8400          0.60       78.53    0.79\n",
      "  4    8600          0.49       76.59    0.77\n",
      "  4    8800          0.51       77.32    0.77\n",
      "  4    9000          0.64       78.88    0.79\n",
      "  5    9200          0.41       80.15    0.80\n",
      "  5    9400          0.49       79.01    0.79\n",
      "  5    9600          0.34       79.62    0.80\n",
      "  5    9800          0.49       79.66    0.80\n",
      "  5   10000          0.25       80.90    0.81\n",
      "  5   10200          0.32       80.08    0.80\n",
      "  5   10400          0.25       80.45    0.80\n",
      "  5   10600          0.50       81.57    0.82\n",
      "  6   10800          0.47       79.23    0.79\n",
      "  6   11000          0.52       80.72    0.81\n",
      "  6   11200          0.28       80.05    0.80\n",
      "  6   11400          0.52       82.50    0.83\n",
      "  6   11600          0.48       81.05    0.81\n",
      "  6   11800          0.20       82.33    0.82\n",
      "  6   12000          0.65       81.12    0.81\n",
      "  7   12200          0.24       81.31    0.81\n",
      "  7   12400          0.25       81.71    0.82\n",
      "  7   12600          0.32       79.96    0.80\n",
      "  7   12800          0.48       81.72    0.82\n",
      "  7   13000          0.39       82.01    0.82\n",
      "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
      "data/textcat_output/model-last\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy train config/config.cfg --verbose --output data/textcat_output --paths.train data/spacy_data/textcat_train.spacy --paths.dev data/spacy_data/textcat_valid.spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91013e68-6abf-4d31-82da-784e563e6de5",
   "metadata": {},
   "source": [
    "#### Model Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "52ae7ac4-9542-42a4-a7be-b25947ffd74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spacy_pred(dict):\n",
    "  largest_value = max(dict.values())\n",
    "  return list(dict.keys())[list(dict.values()).index(largest_value)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5b7d1dcf-5050-4f45-982b-b100084af76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify model for English model\n",
    "nlp_model = spacy.load(\"data/textcat_output/model-best\")\n",
    "test_text = test_data.text.tolist()\n",
    "test_cats = test_data.top_label.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "bc29fb87-0c95-4393-a748-6d2c37c60f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2014/2014 [00:00<00:00, 2620.04it/s]\n"
     ]
    }
   ],
   "source": [
    "pred_list = []\n",
    "for item in tqdm(test_text, total=len(test_text)):\n",
    "    doc = nlp_model(item)\n",
    "    pred = get_spacy_pred(doc.cats)\n",
    "    pred_list.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6042b821-3ac5-4f56-9034-13793d18ccf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "73a3f404-bd3f-4f1c-8a8d-c4c33a59f655",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9272686201100564"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(test_cats, pred_list, average='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c0b817-a469-493d-b2d4-0df84fc764aa",
   "metadata": {},
   "source": [
    "> In addition to the above model we can also use **en_core_web_trf** model as the nlp model in spacy for improved performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad43242-a789-4d01-942e-1f7a9d4f567d",
   "metadata": {},
   "source": [
    "> Spacy also supports GPU support and trnsformer based models in the pipeline. In addition it also supports the recent developments in LLM space for any NLP apctivities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3248bdd-33ff-44db-b656-9f903a55f58f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
